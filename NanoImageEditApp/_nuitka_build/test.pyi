# This file was generated by Nuitka

# Stubs included by default
from __future__ import annotations
from PIL import Image
from contextlib import contextmanager
from typing import Any, Dict, List, Optional, Tuple, Union
from typing_extensions import Self
import PIL.Image
import argparse
import gc
import logging
import os
import sys
import time
import torch
import torch.nn

def get_cuda_memory_info(device: torch.device) -> Dict[str, float]:
    ...

def log_cuda_memory(label: str, device: torch.device) -> Any:
    ...

def clear_memory(device: torch.device) -> Any:
    ...

def reset_peak_memory(device: torch.device) -> Any:
    ...

class StreamingFlux2Transformer:
    def __init__(self: Self, transformer: nn.Module, device: torch.device, dtype: torch.dtype) -> None: ...
    def prepare_streaming(self: Self) -> Any: ...
    @staticmethod
    def _move_to_pinned_cpu(module: nn.Module) -> Any: ...
    def _prefetch_block(self: Self, block: nn.Module) -> Any: ...
    def _offload_block(self: Self, block: nn.Module) -> Any: ...
    def _stream_blocks(self: Self, blocks: Any, forward_fn: Any) -> Any: ...
    def __call__(self: Self, hidden_states: torch.Tensor, encoder_hidden_states: torch.Tensor, timestep: torch.LongTensor, img_ids: torch.Tensor, txt_ids: torch.Tensor, guidance: torch.Tensor, joint_attention_kwargs: dict, return_dict: bool) -> Any: ...
    def cleanup(self: Self) -> Any: ...

def load_pipeline(model_id: str, dtype: torch.dtype) -> Any:
    ...

def _patch_execution_device(pipe: Any, device: torch.device) -> Any:
    ...

def setup_streaming_pipeline(pipe: Any, device: torch.device, dtype: torch.dtype, prompt: str, guidance_scale: float, max_sequence_length: int) -> Any:
    ...

def run_standard_inference(model_id: str, prompt: str, height: int, width: int, num_steps: int, guidance_scale: float, seed: int, dtype: torch.dtype, device: torch.device, image: Optional[Union[PIL.Image.Image, List[PIL.Image.Image]]]) -> Dict[str, Any]:
    ...

def run_streaming_inference(model_id: str, prompt: str, height: int, width: int, num_steps: int, guidance_scale: float, seed: int, dtype: torch.dtype, device: torch.device, image: Optional[Union[PIL.Image.Image, List[PIL.Image.Image]]]) -> Dict[str, Any]:
    ...

def print_comparison(standard: Dict[str, Any], streaming: Dict[str, Any]) -> Any:
    ...

def main() -> Any:
    ...


__name__ = ...



# Modules used internally, to allow implicit dependencies to be seen:
import os
import sys
import gc
import time
import argparse
import logging
import typing
import contextlib
import torch
import torch.nn
import PIL
import PIL.Image
import diffusers
import diffusers.models
import diffusers.models.modeling_outputs
import diffusers.Flux2KleinPipeline
import base64